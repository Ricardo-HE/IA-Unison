{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagenes/ia.png\", width=\"200\" \\>\n",
    "# Comparación de diferentes clasificadores\n",
    "\n",
    "[**Julio Waissman Vilanova**](http://mat.uson.mx/~juliowaissman/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta libreta se muestra para 3 conjuntos de datos artificiales bidimensionales, la forma en que se realiza la clasificación con distintos métodos. Principalmente lo hacemos para poder sacar conclusiones sobre en que situaciones un método puede ser mejor que otros, y que está haciendo internamente.\n",
    "\n",
    "Codigo obtenido de la documentación de scikit-learn, el cual se puede consultar [aquí](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69de58d65c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Para separar los datos en entrenamiento y validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Para normalizar los datos (desviación estandar)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.model_selection"
     ]
    }
   ],
   "source": [
    "# El de base\n",
    "import numpy as np\n",
    "\n",
    "# Las gráficas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Para separar los datos en entrenamiento y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Para normalizar los datos (desviación estandar)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Los conjuntos de datos artificiales típicos para probar clasificadores\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "# Los métodos de aprendizaje a utilizar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fcf5785d3ec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Para separar los datos en entrenamiento y validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.model_selection"
     ]
    }
   ],
   "source": [
    "\n",
    "# Para separar los datos en entrenamiento y validación\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generando los 3 conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Del modulo para general conjuntos de datos artificiales, para hacer conjuntos de lunas y circulos:\n",
    "lunas = make_moons(noise=0.3, random_state=0)\n",
    "circulos = make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "# Ahora generamos un conjunto de datos linealmente separables\n",
    "X, y = make_classification(n_features=2,             #  Dos dimensiones para poderlos graficar \n",
    "                           n_redundant=0,            #  Sin dimensiones redundantes, no nos interesa probar esto ahora\n",
    "                           n_informative=2,          #  Las dos dimensiones informativas (no correlacionadas)\n",
    "                           random_state=1,           #  Semilla, siempre la misma para que todos tengan los mismos resultados\n",
    "                           n_clusters_per_class=1)   #  Una sola forma por clase para hacerlo más sencillo\n",
    "\n",
    "# Le agregamos ruido a la separación lineal (algunos puntos mal clasificados)\n",
    "rng = np.random.RandomState(2)           #  Un generados de números pseudoaleatorios con la semilla impuesta\n",
    "X += 2 * rng.uniform(size=X.shape)       #  A cada punto se le suma un error con una distribución uniforme en ambas dimensiones\n",
    "lineal = (X, y)\n",
    "\n",
    "datasets = [lunas, circulos, lineal]    # Una lista de tuplas (X, y)\n",
    "\n",
    "# Y los grafiacamos para verlos\n",
    "figure = plt.figure(figsize=(30, 10))\n",
    "cm_escala = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "for (i, ds) in enumerate(datasets):\n",
    "\n",
    "    # Selecciona los valores del conjunto de datos y los escala\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Grafica\n",
    "    ax = plt.subplot(1, 3, i+1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=150, cmap=cm_escala)\n",
    "    ax.set_xlim(X[:, 0].min() - .5, X[:, 0].max() + .5)\n",
    "    ax.set_ylim(X[:, 1].min() - .5, X[:, 1].max() + .5)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "figure.subplots_adjust(left=.02, right=.98)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define la bateria de clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = [u\"Vecinos próximos\", \"SVM lineal\", \"SVM gaussiano\", u\"Árbol de desición\",\n",
    "           u\"Boseques aleatórios\", \"AdaBoost\", \"Naive Bayes\", \"Discriminante lineal\",\n",
    "           \"Discriminante cuadrátco\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generando la clasificación con cada método diferente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar por cada conjunto de datos datos de entrenamiento y prueba, y aparte vamos a clasificar todos los datos dentro del meshgrid, para asignarles colores en el fondo, que nos permitan visualizar el tipo de particiones del plano que se genera con cada uno de los métodos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Colores brillantes\n",
    "cm = plt.cm.RdBu\n",
    "cm_escala = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "for (cual, ds) in enumerate(datasets):\n",
    "    \n",
    "    print(\"Base de datos {}\".format(cual))\n",
    "    figure = plt.figure(figsize=(30, 30))\n",
    "\n",
    "    # Escalar y selecciona valores de entrenamiento y prueba\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Dividir el conjunto en un conjunto de entrenamiento y otro de aprendizaje\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    # Meshgrid para clasificar toda la región y pintar las regiones\n",
    "    xx, yy = np.meshgrid(np.arange(X[:, 0].min() - .5, X[:, 0].max() + .5, 0.02),\n",
    "                         np.arange(X[:, 1].min() - .5, X[:, 1].max() + .5, 0.02))\n",
    "\n",
    "    # Por cada clasificador\n",
    "    for (i, (titulo, clf)) in enumerate(zip(titulos, classifiers)):\n",
    "        \n",
    "        # Escoge el subplot\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        \n",
    "        # El entrenamiento!!!!\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Encuentra el error de validación\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Clasifica cada punto en el meshgrid\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Asigna un color a cada punto\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Grafica los datos de entrenamiento y prueba\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_escala, s=150)\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_escala, s=150, alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(titulo, size=30)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=30, horizontalalignment='right')\n",
    "\n",
    "    figure.subplots_adjust(left=.02, right=.98)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generando un conjunto de datos en forma de espiral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Inicialización de datos\n",
    "np.random.seed(0) # Aseguramos que siempre pasa lo mismo\n",
    "N = 100 # Ejemplos por clase\n",
    "D = 2 # Atributos\n",
    "K = 3 # Clases\n",
    "X = np.zeros((N * K, D))\n",
    "Y = np.zeros((N * K, 1), dtype='uint8')\n",
    "\n",
    "# Genera datos en espiral\n",
    "for clase in range(K):\n",
    "  ix = list(range(N*clase, N*(clase+1)))  # Indices para cada clase\n",
    "  r = np.linspace(0.0, 1, N) \n",
    "  t = np.linspace(clase * 4, (clase + 1) * 4, N) + np.random.randn(N) * 0.2 \n",
    "  X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n",
    "  Y[ix] = clase\n",
    "\n",
    "\n",
    "#  Grafica datos\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=40, cmap=plt.cm.spring)\n",
    "plt.title(\"Datos sintéticos en forma de espiral\")\n",
    "plt.xlim(X[:, 0].min() - .5, X[:, 0].max() + .5)\n",
    "plt.ylim(X[:, 1].min() - .5, X[:, 1].max() + .5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio:\n",
    "\n",
    "Prueba los diferentes clasificadores para este conjunto de datos. Recuerda que en este caso tenemos un problema de múltiples clases y los métodos podrían necesitar un ajuste especial. Clasifica un grid con los puntos que permitan estudiar la forma de la partición del esacio, tal como se hizo en el ejemplo.\n",
    "\n",
    "Revisa la literatura de cada método en caso que no funcionen directamente. Agrega a continuación el código que genera las gráficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega aqui tu códgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "### Ejercicio:\n",
    "\n",
    "Escribe a continuación tus conlusiones, agreando lo siguiente:\n",
    "\n",
    "1. Para cada clasificador, ¿Como es la partición del espacio que genera?\n",
    "2. ¿Para que casos crees que son mejores unos clasificadores a otros?\n",
    "3. Existen clasificadores que se comporten más o menos parecido? ¿Los podrías regrupar?\n",
    "4. ¿Hay algún clasificador que, vista la evidencia, ni siquiera probarías al principio? ¿Cúal(es? ¿Porqué?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
